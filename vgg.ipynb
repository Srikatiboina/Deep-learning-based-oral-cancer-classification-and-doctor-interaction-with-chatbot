{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import * \n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set='train'\n",
    "val_set='val'\n",
    "test_set='test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = image.ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1\n",
    ")\n",
    "validation_datagen= image.ImageDataGenerator(    rotation_range=15,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1)\n",
    "test_datagen= image.ImageDataGenerator(    rotation_range=15,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 90 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n",
      "Found 21 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# image addressing\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_set,\n",
    "    target_size = (224,224),\n",
    "    batch_size = 8,\n",
    "    class_mode = 'binary')\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    val_set,\n",
    "    target_size = (224,224),\n",
    "    batch_size = 8,\n",
    "    shuffle=True,\n",
    "    class_mode = 'binary')\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_set,\n",
    "    target_size = (224,224),\n",
    "    batch_size = 8,\n",
    "    class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cancer': 0, 'non-cancer': 1}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 5s 0us/step\n"
     ]
    }
   ],
   "source": [
    "base_for_model = tf.keras.applications.VGG16(weights='imagenet', input_shape=(224,224,3), include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_for_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Functional)           (None, 7, 7, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "gaussian_noise (GaussianNois (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 14,979,905\n",
      "Trainable params: 264,193\n",
      "Non-trainable params: 14,715,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(base_for_model) \n",
    "model.add(GaussianNoise(0.25)) #to prevent overfitting\n",
    "model.add(GlobalAveragePooling2D()) #to converge and reduce the parameters\n",
    "model.add(Dense(512, activation = 'relu')) #hidden layer (relu activation function is suggested for images)\n",
    "model.add(BatchNormalization()) #to prevent overfitting\n",
    "model.add(Dense(1, activation='sigmoid')) #output layer\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam= tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=adam,loss= 'binary_crossentropy', metrics=['accuracy','Precision','Recall','AUC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp= tf.keras.callbacks.ModelCheckpoint(filepath='mymodel.hdf5', \n",
    "                               verbose=2, save_best_only=True)\n",
    "es= tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.05, patience=3)\n",
    "callback=[es,mp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " 9/80 [==>...........................] - ETA: 1:35 - loss: 0.7287 - accuracy: 0.6818 - precision: 0.5172 - recall: 0.6818 - auc: 0.7221"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PERSONAL\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\PIL\\Image.py:993: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/80 [===>..........................] - ETA: 1:37 - loss: 0.6873 - accuracy: 0.6778 - precision: 0.5122 - recall: 0.7000 - auc: 0.7450WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 1600 batches). You may need to use the repeat() function when building your dataset.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.41388, saving model to mymodel.hdf5\n",
      "12/80 [===>..........................] - 22s 2s/step - loss: 0.6873 - accuracy: 0.6778 - precision: 0.5122 - recall: 0.7000 - auc: 0.7450 - val_loss: 0.4139 - val_accuracy: 0.8500 - val_precision: 1.0000 - val_recall: 0.5714 - val_auc: 0.9341\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=80, #steps_per_epoch= training_images/batch_size= 4946/8<=618\n",
    "    epochs = 20, #own choice\n",
    "    validation_data = validation_generator,\n",
    "    callbacks=callback\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'auc', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_auc'])\n"
     ]
    }
   ],
   "source": [
    "print(history.history.keys())\n",
    "import matplotlib.pyplot as plt\n",
    "acc=(history.history['accuracy'])\n",
    "loss=(history.history['loss'])\n",
    "prc=(history.history['precision'])\n",
    "rec=(history.history['recall'])\n",
    "auc=(history.history['auc'])\n",
    "val_acc=(history.history['val_accuracy'])\n",
    "val_loss=(history.history['val_loss'])\n",
    "val_prc=(history.history['val_precision'])\n",
    "val_rec=(history.history['val_recall'])\n",
    "val_auc=(history.history['val_auc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 17s 1s/step - loss: 0.3352 - accuracy: 0.8889 - precision: 0.9545 - recall: 0.7000 - auc: 0.9622\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.33524152636528015,\n",
       " 0.8888888955116272,\n",
       " 0.9545454382896423,\n",
       " 0.699999988079071,\n",
       " 0.962222158908844]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 2s 698ms/step - loss: 0.4468 - accuracy: 0.8500 - precision: 0.8333 - recall: 0.7143 - auc: 0.9505\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4467600882053375,\n",
       " 0.8500000238418579,\n",
       " 0.8333333134651184,\n",
       " 0.7142857313156128,\n",
       " 0.9505494832992554]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 2s 799ms/step - loss: 0.4292 - accuracy: 0.8571 - precision: 0.8333 - recall: 0.7143 - auc: 0.9388\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4291858673095703,\n",
       " 0.8571428656578064,\n",
       " 0.8333333134651184,\n",
       " 0.7142857313156128,\n",
       " 0.9387755393981934]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "predictions = model.predict(test_generator)\n",
    "test_generator.classes\n",
    "cm = confusion_matrix(test_generator.classes, predictions.round())\n",
    "\n",
    "sns.heatmap(cm,  annot=True, fmt=\"d\" ,cmap=\"YlGnBu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.71      0.67        14\n",
      "           1       0.20      0.14      0.17         7\n",
      "\n",
      "    accuracy                           0.52        21\n",
      "   macro avg       0.41      0.43      0.42        21\n",
      "weighted avg       0.48      0.52      0.50        21\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(test_generator.classes, predictions.round())) #.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'load_img'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_204\\2596507846.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'C:\\Users\\PERSONAL\\Desktop\\oral cancer\\data\\non-cancer\\_tongue.jpg'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtarget_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m224\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m224\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mimaga\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimaga\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mypred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mypred\u001b[0m\u001b[1;33m<\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'load_img'"
     ]
    }
   ],
   "source": [
    "img = image.load_img(r'C:\\Users\\PERSONAL\\Desktop\\oral cancer\\data\\non-cancer\\_tongue.jpg',target_size=(224,224))\n",
    "imaga = image.img_to_array(img)\n",
    "image = np.expand_dims(imaga,axis=0)  \n",
    "ypred = model.predict(image)\n",
    "if ypred<0.5:\n",
    "      ypred=\"non-cancer\"\n",
    "else:\n",
    "      ypred=\"cancer\" \n",
    "plt.imshow(img)\n",
    "ypred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
